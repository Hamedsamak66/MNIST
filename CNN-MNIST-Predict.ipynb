{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSrkA2r6kULxWD54uQ2tKG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamedsamak66/MNIST/blob/main/CNN-MNIST-Predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2KtkOCm42Bl2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv-iPbww2NzI",
        "outputId": "f0f65f1b-4958-4fe6-8575-a5c08457d261"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the pixel values to the range [0, 1]\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "5vtFgKfO2Tkz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Reshape the images for the CNN\n",
        "X_train_cnn = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test_cnn = X_test.reshape(X_test.shape[0], 28, 28, 1)"
      ],
      "metadata": {
        "id": "jt6EKIC12WkD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the images for the models that require 1D input\n",
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_flat = X_test.reshape(X_test.shape[0], -1)"
      ],
      "metadata": {
        "id": "buhoU73J2bnL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the target labels\n",
        "y_train_onehot = to_categorical(y_train, 10)\n",
        "y_test_onehot = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "EbHZnsAn2cuL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define preprocessing techniques\n",
        "preprocessing_techniques = {\n",
        "    'StandardScaler': StandardScaler(),\n",
        "    'MinMaxScaler': MinMaxScaler()\n",
        "}"
      ],
      "metadata": {
        "id": "AsCgUME52f-s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural network model\n",
        "def create_nn_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=input_shape),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# CNN model\n",
        "def create_cnn_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "tyJ7knTB2iau"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Other models\n",
        "models = {\n",
        "    'RandomForestClassifier': RandomForestClassifier(),\n",
        "    'SVC': SVC(),\n",
        "    'NeuralNetwork': create_nn_model((28, 28)),\n",
        "    'CNN': create_cnn_model((28, 28, 1))\n",
        "}"
      ],
      "metadata": {
        "id": "Qjn_RyXD2oPA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate each model with each preprocessing technique\n",
        "def evaluate_models(preprocessing_techniques, models, X_train_flat, X_test_flat, X_train_cnn, X_test_cnn, y_train, y_test):\n",
        "    results = []\n",
        "    for prep_name, prep in preprocessing_techniques.items():\n",
        "        for model_name, model in models.items():\n",
        "            if model_name == 'NeuralNetwork':\n",
        "                # Handle neural network separately\n",
        "                model = create_nn_model((784,))\n",
        "                X_train_prep = prep.fit_transform(X_train_flat)\n",
        "                X_test_prep = prep.transform(X_test_flat)\n",
        "                model.fit(X_train_prep, y_train_onehot, epochs=5, batch_size=32, verbose=0)\n",
        "                y_pred = model.predict(X_test_prep)\n",
        "                # Convert predictions to class labels\n",
        "                y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "                accuracy = accuracy_score(y_test, y_pred_labels)\n",
        "                results.append((prep_name, model_name, accuracy))\n",
        "            elif model_name == 'CNN':\n",
        "                # Handle CNN separately\n",
        "                model = create_cnn_model((28, 28, 1))\n",
        "                model.fit(X_train_cnn, y_train_onehot, epochs=5, batch_size=32, verbose=0)\n",
        "                y_pred = model.predict(X_test_cnn)\n",
        "                # Convert predictions to class labels\n",
        "                y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "                accuracy = accuracy_score(y_test, y_pred_labels)\n",
        "                results.append((prep_name, model_name, accuracy))\n",
        "            else:\n",
        "                pipeline = Pipeline([\n",
        "                    (prep_name, prep),\n",
        "                    (model_name, model)\n",
        "                ])\n",
        "                pipeline.fit(X_train_flat, y_train)\n",
        "                y_pred = pipeline.predict(X_test_flat)\n",
        "                accuracy = accuracy_score(y_test, y_pred)\n",
        "                results.append((prep_name, model_name, accuracy))\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "gS5u4wGZ2uIL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the models\n",
        "results = evaluate_models(preprocessing_techniques, models, X_train_flat, X_test_flat, X_train_cnn, X_test_cnn, y_train, y_test)\n",
        "\n",
        "# Convert results to a DataFrame for better readability\n",
        "results_df = pd.DataFrame(results, columns=['Preprocessing', 'Model', 'Accuracy'])\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWUeDkBq22BO",
        "outputId": "799fad9c-1bb8-414b-9720-2a1e291568e1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "    Preprocessing                   Model  Accuracy\n",
            "0  StandardScaler  RandomForestClassifier    0.9694\n",
            "1  StandardScaler                     SVC    0.9661\n",
            "2  StandardScaler           NeuralNetwork    0.9688\n",
            "3  StandardScaler                     CNN    0.9852\n",
            "4    MinMaxScaler  RandomForestClassifier    0.9688\n",
            "5    MinMaxScaler                     SVC    0.9792\n",
            "6    MinMaxScaler           NeuralNetwork    0.9737\n",
            "7    MinMaxScaler                     CNN    0.9869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the best preprocessing and model combination based on accuracy score\n",
        "best_result = results_df.loc[results_df['Accuracy'].idxmax()]\n",
        "print(f\"Best Preprocessing Technique: {best_result['Preprocessing']}\")\n",
        "print(f\"Best Model: {best_result['Model']}\")\n",
        "print(f\"Best Accuracy: {best_result['Accuracy']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5-k0MyF3FHA",
        "outputId": "60134223-d170-423b-8798-225a120f4697"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Preprocessing Technique: MinMaxScaler\n",
            "Best Model: CNN\n",
            "Best Accuracy: 0.9869\n"
          ]
        }
      ]
    }
  ]
}